version: '3.9'
networks:
  upload-parquet-to-s3:
    driver: bridge
    ipam:
      config:
        - subnet: 172.18.0.0/16
          gateway: 172.18.0.1

services:
  spark-master:
    build:
      context: .
      dockerfile: miscellaneous/Dockerfile
    container_name: spark-master
    ports:
      - "8083:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - AWSAccessKey=${AWSAccessKey}
      - AWSSecretKey=${AWSSecretKey}
      - AWSSessionToken="${AWSSessionToken}"
      - AWS_REGION=${AWS_REGION}
      - INPUT_PATH=${INPUT_PATH}
      - SCHEMA_PATH=${SCHEMA_PATH}
      - SERVER=${SERVER}
      - UID="${UID}"
      - PASSWORD="${PASSWORD}"
      - DB="${DB}"
      #- XConection=${XConection}
      #- Query=${Query}
      - ConnectorType="${ConnectorType}"
      - driverClassPath="${driverClassPath}"
      - Table=${Table}
      - Country="${Country}"
      - Route="${Route}"
      #- TimePeriod="${TimePeriod}"
      - BucketName="${BucketName}"
      - BucketRoute="${BucketRoute}"
      #- Bucket="${Bucket}"
      #- FileName="${FileName}"
      - ChunkSize="${ChunkSize}"
      #- Driver="${Driver}"
      - Port="${Port}"
    deploy:
      resources:
        limits:
          memory: 4g # Limita la cantidad de memoria del contenedor a 6GB
    volumes:
      - ./:/app
    command: [
        "spark-submit", 
        #"--packages","org.apache.hadoop:hadoop-aws:3.3.5",
        "--master", "local[*]",
        "--deploy-mode", "client",
        "--conf","spark.driver.extraClassPath=/app/libs/hadoop-aws-3.3.5.jar",
        "--conf","spark.executor.extraClassPath=/app/libs/hadoop-aws-3.3.5.jar",
        "--conf", "spark.driver.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4=true -Dcom.amazonaws.services.s3.enforceV4=true -Dcom.amazonaws.services.s3.useRequestSignature=false",
        "--driver-class-path", "${driverClassPath}",
        "--executor-memory", "4g", 
        "--driver-memory", "2g", 
        "/app/uploadParquetToS3.py",
        "-S","${SERVER}",
        "-U","${UID}",
        "-P","${PASSWORD}",
        "-DB","${DB}",
        #"-X","${XConection}",
        #"-Q","${Query}",
        "-T","${Table}",
        "-C","${Country}",
        "-R","${Route}",
        #"-PE","${TimePeriod}",
        "-AA","${AWSAccessKey}",
        "-AS","${AWSSecretKey}",
        "-TK","${AWSSessionToken}",
        "-B","${BucketName}",
        "-BR","${BucketRoute}",
        #"-BK","${Bucket}",
        #"-FN","${FileName}",
        "-CS","${ChunkSize}",
        "-CT","${ConnectorType}",
        "-DR","${Driver}",
        "-PO","${Port}"
      ]
    networks:
      upload-parquet-to-s3:
        ipv4_address: 172.18.0.2
  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://172.18.0.2:7077"
    networks:
      upload-parquet-to-s3:
        ipv4_address: 172.18.0.3
    volumes:
      - ./:/app
    deploy:
      resources:
        limits:
          memory: 4g # Limita la cantidad de memoria del contenedor a 6GB
  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://172.18.0.2:7077"
    networks:
      upload-parquet-to-s3:
        ipv4_address: 172.18.0.4
    volumes:
      - ./:/app
    deploy:
      resources:
        limits:
          memory: 4g # Limita la cantidad de memoria del contenedor a 6GB
  spark-history-server:
      image: bde2020/spark-history-server:3.3.0-hadoop3.3
      container_name: spark-history-server
      depends_on:
        - spark-master
      ports:
        - "18081:18081"
      volumes:
        - /tmp/spark-events-local:/tmp/spark-events
        - ./:/app
      networks:
        upload-parquet-to-s3:
          ipv4_address: 172.18.0.5
      deploy:
        resources:
          limits:
            memory: 4g # Limita la cantidad de memoria del contenedor a 6GB